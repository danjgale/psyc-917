{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-Level Analysis\n",
    "\n",
    "This lesson is one of two lessons on how to run conventional mass-univariate analyses using general linear models (called GLM analysis). Let's break this down. Mass-univariate refers to performing univariate analysis on each voxel. The way this is often done is by fitting a GLM to each voxel, although there are certainly other statistical approaches you can do. In doing so, mass-univariate analysis can identify voxels in the brain that are 'modulated' or differentially 'activated' by a task. This is sometimes called 'blobology' because it generates 'blobs', or clusters, in the brain of significant voxels. \n",
    "\n",
    "Pretty much all fMRI analyses involve some sort of analysis on the individual subjects (first-level analysis), which is followed by some sort of group-analysis (second-level analysis). The latter seeks to identify group-level effects of whatever was done in the former. \n",
    "\n",
    "This lesson focuses on first-level GLM analysis--that is, taking a subject's brain and fitting GLMs for each of their voxels. We will start by doing a step-by-step walkthrough on one subject. The key here is to really take the time to understand both the concepts and the implementation. When I started, I personally found GLM analyses pretty confusing, so don't worry if you get lost! We will cover each step in detail, one chunk of code at a time.  \n",
    "\n",
    "Afterwards, we'll run first-level analyses on all of the subjects. Subjects' data will be saved and used as input in the next lesson, where we will perform our second-level analysis. The implementation we will use is pretty much what you would do in an actual project. \n",
    "\n",
    "---\n",
    "**A note on other fMRI software**:\n",
    "\n",
    "Typically, people use software such as AFNI, SPM or FSL for mass-univariate analyses. While these packages serve their purpose well, they come with their own set of hurdles:\n",
    "- Each software has their own learning curves\n",
    "- Documentation can be sparse, non-existent, or hard to digest \n",
    "- Practical tutorials and examples can be hard to come by  \n",
    "- Their GUI implementations (FSL and SPM) tend to obfuscate analysis and can be very tedious\n",
    "- SPM requires a MATLAB license, and AFNI and FSL cannot be run directly on Windows\n",
    "\n",
    "As noted in previous lessons, I recommend trying out one of these software packages in your own time just to get a sense of what's out there. They're full fMRI packages that each come with some excellent tools, which can come in handy. I find myself using FSL and AFNI utilities quite a bit in addition to Python.\n",
    "\n",
    "---\n",
    "\n",
    "We will implement mass-univariate analyses using nilearn. Running mass-univariate analyses is straightforward with nilearn, and importantly, it doesn't hide a lot of details. By being so explicit, it easy to check your steps. I think it does a great job at keep your analyses transparent. \n",
    "\n",
    "Let's start by importing all of our functions. You'll notice that there are many more than previous lessons. We're importing:\n",
    "- numpy and nibabel as usual\n",
    "- glob, which will allow us to pattern match for files\n",
    "- matplotlib just to help with some visualization\n",
    "- pandas, which we'll use to read and adjust some files\n",
    "- nilearn's `glm` functions/classes to set up and run the analysis \n",
    "- pickle, which lets us save Python objects to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.plotting import view_img, plot_design_matrix\n",
    "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. In-depth single subject walkthrough\n",
    "\n",
    "We'll go through each step of performing a first-level analysis of the motor localizer in one subject.  \n",
    "\n",
    "### 1.1. Setting up the data\n",
    "\n",
    "We'll first get the preprocessed functional runs of one task produced by fmriprep. We can use Python's glob module to extract all files matching a template. Basically, it will find all files that match the template in the string, where `*` is a wildcard that says any number of any character can be filled in there. The template we'll provide will give us the preprocessed motor localizer runs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_template = ('data/derivatives/fmriprep/sub-01/func/'\n",
    "                '*task-motor*MNI152NLin2009cAsym*preproc_bold.nii.gz')\n",
    "func_data = glob.glob(glob_template)\n",
    "\n",
    "# reorder these based on run number \n",
    "func_imgs = sorted(list(func_data))\n",
    "func_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will also need the run's motion parameters that were extracted during motion correction in preprocessing. fmriprep stores all of the parameters, along with many others, in the `confounds_regressors.tsv` files. Each run has one of these files. \n",
    "\n",
    "We will use Pandas to load in the file into Python and select only the motion parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_template = ('data/derivatives/fmriprep/sub-01/func/'\n",
    "                '*task-motor*confounds_regressors.tsv')\n",
    "conf_files = glob.glob(glob_template)\n",
    "\n",
    "# reorder these based on run number\n",
    "conf_files = sorted(list(conf_files))\n",
    "\n",
    "# load only the 6 motion parameters into python\n",
    "motion_params = []\n",
    "for conf in conf_files:\n",
    "    conf_data = pd.read_table(conf, usecols=['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z'])\n",
    "    motion_params.append(conf_data)\n",
    "\n",
    "# show the first one\n",
    "motion_params[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Defining the model\n",
    "\n",
    "Before we set up a model, let's load in a brain mask of the MNI template. This mask will restrict analysis to voxels only inside the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mask = nib.load('MNI_brain_mask.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will specify our model. Nilearn makes it really easy to specify a GLM. The `FirstLevelModel` class let's you define all your parameters in one step, and then you can use it's methods to fit the model and define contrasts. \n",
    "\n",
    "The [online documentation](https://nilearn.github.io/stable/modules/generated/nilearn.glm.first_level.FirstLevelModel.html#nilearn.glm.first_level.FirstLevelModel) for the `FirstLevelModel` gives a description for each parameter. For our analysis, a few things are required:\n",
    "- The TR, which is 2s\n",
    "- The HRF model, in which there are several to choose from (see documentation for the options). We will choose Glover's (1999) canonical HRF along with the temporal derivative. Adding the derivative is often recommended to improve model fit. The option we'll use is 'glover + derivative'. \n",
    "- We also want to apply some additional processing steps, on top of what was done with fmriprep. We will scale and temporally filter the data (0.01Hz), and spatially smooth the data using a 6mm FWHM kernel. \n",
    "- The brain mask we just loaded\n",
    "\n",
    "Some of the above options are the default parameters, but we'll explicitly specify them. \n",
    "\n",
    "When you run this, nothing will happen! Running the below command simply configures the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FirstLevelModel(t_r=2, hrf_model='glover + derivative', high_pass=.01, \n",
    "                        signal_scaling=0, smoothing_fwhm=6,\n",
    "                        mask_img=brain_mask, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 The model design\n",
    "\n",
    "The design matrix is what defines our regressors. We are trying to _predict actual brain activity_ using an a model of activity that we would expect to arise from the task. Each condition (AKA trial type) is defined as a single regressor. In our case, we will have 8 task regressors of interest (Arm, Eye, Finger, Grasp, Mouth, Speech, Toes, Touch). The remaining regressors are there to either improve model fit or regress out noise (i.e. act as temporal filters).\n",
    "\n",
    "In nilearn, there are a few different ways to build a design matrix. You can build one directly using the `make_first_level_design_matrix` function (see [documentation](https://nilearn.github.io/stable/modules/generated/nilearn.glm.first_level.make_first_level_design_matrix.html#nilearn.glm.first_level.make_first_level_design_matrix)). I'd recommend trying this in your own time because it's nice to build your design matrix and inspect it before running your analysis.\n",
    "\n",
    "For this lesson, we'll use the much simpler way of specifying a design matrix: we will by pass in events files when fitting the model. The downside to this approach is that we can only inspect our design matrix _after_ the model has finished fitting.\n",
    "\n",
    "Let's load in the events files that tell us each trial/block's onset, duration, and condition. There is one events file for each run, which we can load in a for-loop using pandas' `read_table` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_files = glob.glob('data/task-motor*events.tsv')\n",
    "event_files = sorted(list(event_files))\n",
    "\n",
    "events = []\n",
    "for ev in event_files:\n",
    "    events.append(pd.read_table(ev))\n",
    "\n",
    "# show the first 10 rows\n",
    "events[0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this is a block design (each block 20s each) with  and that there are 32 blocks (4 each condition). When we pass this DataFrame into our model, it will be transformed to a proper design matrix.\n",
    "\n",
    "### 1.4 Fitting the model\n",
    "\n",
    "We fit the model (or specifically, the model for each voxel) by calling the `.fit()` method. In this method, we pass in the functional image, our events data, and the motion parameters that we saved earlier. Note that this will produce a bunch of warnings--ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(func_imgs, events=events, confounds=motion_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've run our model, we can inspect the design matrix. _It's really important to check your design matrix to ensure that it is correct_. Small errors, which can easily be spotted by looking at the design matrix in the design, can have large effects on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design = model.design_matrices_[0]\n",
    "fig, ax = plt.subplots(figsize=(13, 8))\n",
    "plot_design_matrix(design, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(design['Arm'])\n",
    "ax.set(title='Arm', xlabel='Time (s)', ylabel='Signal (a.u.)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The design matrix accurately reflects what we saw in the events file. \n",
    "\n",
    "### 1.5 Inspecting regression coefficients\n",
    "\n",
    "Next we can look at the regression coefficients. If we look at the 'Arm' condition, we can see which voxels match closely to our 'Arm' regressor. That is, voxels with large positive values are likely modulated by an arm movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_map = model.compute_contrast('Arm', output_type='effect_size')\n",
    "view_img(beta_map, resampling_interpolation='nearest', vmax=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Putting it all together \n",
    "\n",
    "We'll copy and paste what we did earlier all into one notebook cell. Everything will be in one for-loop that iterates through each subject. Exactly like before, we'll do the following for each subject:\n",
    "1. Get the subject's functional images and load them\n",
    "2. Get the subject's 6 motion parameters\n",
    "3. Set up a model identical to the one we were using before\n",
    "\n",
    "The events files are the same across subjects, so we don't need to load those in again. We can just reuse them for each subject. As such, we don't need to plot the design matrix for each subject either.\n",
    "\n",
    "In the glob templates for steps 1) and 2), you'll notice that the string starts with an `f` and contains curly braces: `{subject}`. Python will place the `subject` variable of the iteration into the string (e.g., `'01` in the first iteration of the for-loop). \n",
    "\n",
    "Note: If you're unfamiliar with for-loops or large chunks of code, don't be alarmed. Take the time to go through each line and identify it's purpose. All we're doing here is applying the same things as earlier, just one at a time for all subjects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_numbers = ['01', '02', '03', '04', '05', '06', '07', '08']\n",
    "columns = ['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z']\n",
    "\n",
    "glms = []\n",
    "for subject in subject_numbers:\n",
    "    \n",
    "    ## 1. Get the functional images in order\n",
    "    glob_template = (f'data/derivatives/fmriprep/sub-{subject}/func/'\n",
    "                     '*task-motor*MNI152NLin2009cAsym*preproc_bold.nii.gz')\n",
    "    func_imgs = glob.glob(glob_template)\n",
    "    func_imgs = sorted(list(func_imgs))\n",
    "    \n",
    "    # 2. Get the regressors\n",
    "    glob_template = (f'data/derivatives/fmriprep/sub-{subject}/func/'\n",
    "                      '*task-motor*confounds_regressors.tsv')\n",
    "    conf_files = glob.glob(glob_template)\n",
    "    # put files in order\n",
    "    conf_files = sorted(list(conf_files))\n",
    "\n",
    "    # load only the 6 motion parameters\n",
    "    motion_params = []\n",
    "    for conf in conf_files:\n",
    "        conf_data = pd.read_table(conf, usecols=columns)\n",
    "        motion_params.append(conf_data)\n",
    "    \n",
    "    \n",
    "    # 3. run model with the same parameters\n",
    "    model = FirstLevelModel(t_r=2, hrf_model='glover + derivative', high_pass=.01, \n",
    "                           signal_scaling=0, smoothing_fwhm=6, mask_img=brain_mask)\n",
    "    # events are the same as we used in our waltkthrough\n",
    "    model.fit(func_imgs, events=events, confounds=motion_params)\n",
    "    glms.append(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Saving the models \n",
    "\n",
    "We'll save these models to a file to use them for next week when perform a second-level analysis and discuss multiple comparisons. We can save Python objects to disk using the [pickle package](https://docs.python.org/3/library/pickle.html) that comes as part of the Python standard library. A pickle file (`.p`) is Python's equivalent to MATLAB's `.mat` or R's `.Rdata`. Much like how we can pickle a vegetable for long-term storage, we can pickle Python objects :). \n",
    "\n",
    "The file we will make will be ~6GB because it contains everything belonging to our first-level models. Make sure you have the space available. In a typical project it makes sense to combine first and second level analysis into the same script so that you're not saving off unnecessary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_level_models.p', 'wb') as f:\n",
    "    pickle.dump(glms, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Excercise: Tinkering around with paramters\n",
    "\n",
    "Go back to the step-by-step walkthrough and adjust the paremeters. Try different temporal filtering, scaling, spatial smoothing, HRF models, confound regressors, etc. Refer to the documentation to see what parameters are possible. See what happens to the beta map each time -- are there any substantial differences? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psyc917-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
