{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI Analysis\n",
    "\n",
    "The goal of an ROI analysis is to analyze the beta values for a region of interest. For each subject, we need to compute the mean beta value of that ROI, and then we can use subject means to analyze at the group level. Depending on our hypothesis, we want to see if there are differences between conditions, or simply if the ROI has beta values greater than 0. \n",
    "\n",
    "Why perform an ROI analysis if you have to run a GLM in the first place? The benefit of ROI analysis is that you have some pre-defined regions of interests in mind, and you only want to test those. This is hugely beneficial because you can avoid getting into whole-brain multiple-comparison stuff, which, as we learned, can be pretty tricky. Whereas a whole brain GLM analysis is an exploratory analysis, ROI analyses are mainly confirmatory analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.plotting import plot_stat_map, plot_roi\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_level_models.p', 'rb') as f:\n",
    "    glms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Combining parameter maps\n",
    "\n",
    "First, let's select an example condition. For now, let's do Arms. \n",
    "\n",
    "Then, we need to iterate through each subject and pull out their beta maps for Arms using the `compute_contrast` method we've been using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = 'Arm'\n",
    "\n",
    "param_maps = [] \n",
    "for model in glms:\n",
    "    parameter_map = model.compute_contrast(cond, output_type='effect_size')\n",
    "    param_maps.append(parameter_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Viewing our ROIs\n",
    "\n",
    "I've gone ahead and made some ROIs that will give us some meaningful resuts for the sake of this excercise. Let's plot each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roi('L_Broca.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roi('L_SSc.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roi('L_FEF.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extracting data from an ROI\n",
    "\n",
    "Okay, so now that we have our ROIs, we need to actually extract data from them. Nilearn has an amazing set of classes that make data extraction extremely easy. Masker objects are essential to the next several tutorials. I highly recommend looking at the [nilearn user guide](https://nilearn.github.io/manipulating_images/masker_objects.html) to get a better understanding of what masker objects can do.\n",
    "\n",
    "We will be using the core masker object, `NiftiMasker`. See the [documentation here](https://nilearn.github.io/modules/generated/nilearn.input_data.NiftiMasker.html#nilearn.input_data.NiftiMasker). Notice that we can apply all sorts of preprocessing steps like we've done in with FirstLevelModels. We want the raw values from our images today, but in the following lessons we will be using the masker objects to also apply preprocessing steps. \n",
    "\n",
    "First, we initialize our masker object. We'll pass in one of our ROI masks. Then, we need to call the `fit_transform` method, which will fit the mask to the data and extract out the parameter values of the voxels that inside the ROI. The voxels will be an array with the dimensions N x M, where N = the number of maps (subjects), and M = the number of voxels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up masker\n",
    "masker = NiftiMasker(mask_img='L_Broca.nii.gz')\n",
    "# extract data\n",
    "roi_data = masker.fit_transform(param_maps)\n",
    "\n",
    "roi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to compute the mean beta value for each subject. This will be our subject-level unit of data. We can conveniently do this using the numpy `mean` function, and set `axis=1`. This will compute the means across the columns (voxels) for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_means = np.mean(roi_data, axis=1)\n",
    "roi_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting all conditions\n",
    "\n",
    "Now we'll repeat what we did above, but iterate through each condition. We'll save off our condition data in a dictionary (`condition_means`). Each item in the dictionary will the subjects' mean beta values for a condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['Arm', 'Eye', 'Finger', 'Grasp', 'Mouth', 'Speech', 'Toes', 'Touch']\n",
    "\n",
    "condition_means = {}\n",
    "for cond in conditions:\n",
    "    \n",
    "    # get parameter map of each subject \n",
    "    param_maps = []\n",
    "    for model in glms:\n",
    "        parameter_map = model.compute_contrast(cond, output_type='effect_size')\n",
    "        param_maps.append(parameter_map)\n",
    "        \n",
    "    # set mask and extract\n",
    "    masker = NiftiMasker(mask_img='L_FEF.nii.gz')\n",
    "    roi_data = masker.fit_transform(param_maps)\n",
    "    \n",
    "    # compute mean for each subject and save off\n",
    "    roi_means = np.mean(roi_data, axis=1)\n",
    "    condition_means[cond] = roi_means\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our results are stored nicely in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plotting the results\n",
    "\n",
    "Finally, we want to plot our results so that we can interpret them. Instead of keeping all of our results in a dictionary, we can easily convert it to a pandas `DataFrame` object that we've seen before. Each key of the dictionary will become a column.\n",
    "\n",
    "Putting things in a `DataFrame` not only lets us use Seaborn for plotting (see below), but it also lets us use the many powerful features provided by pandas. We'll use the `describe` method to look at the summary statistics before we plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(condition_means)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to reshape our data into a columnar, or 'long', format. Right now, each column being a condition, and each row is a subject. What we want is for each row to be a single beta value that is labelled according to it's condition. We don't need subject information for our analysis, so we don't need to worry about labeling each beta value according to the subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.melt(var_name='Condition', value_name='Beta')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot this using Seaborn, which is a fantastic statistical plotting library. The [online documentation is excellent](https://seaborn.pydata.org/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Condition', y='Beta', data=results, color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drastically improve this figure in order to make it publication-ready. We'll overlay individual data points, convert the 95% CI to standard error, fix up some styling stuff, and add a title. We'll bundle this all into a matplotlib figure (`fig`), which consists of a single panel (`ax`). We can edit properties of this panel by calling various methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# over lay data points \n",
    "sns.stripplot(x='Condition', y='Beta', data=results, color='k', ax=ax, \n",
    "              edgecolor='k', marker='o', size=4)\n",
    "# make nice bars\n",
    "sns.barplot(x='Condition', y='Beta', data=results, color='dodgerblue', \n",
    "            ci=68, errcolor='k', errwidth=1.5, ax=ax)\n",
    "# add a 0 line\n",
    "ax.axhline(0, c='k', lw=1)\n",
    "# add title and stylize the axes\n",
    "ax.set_title('Left FEF')\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "sns.despine(bottom=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
