{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representational Similarity Analysis\n",
    "\n",
    "Representational similarity analysis (RSA) is a MVPA technique that examines correlations between voxel patterns (i.e between condition A and condition B) to determine their similarity or _dissimilarity_. In the localizer task, we might expect Grasp and Arm to have similar patterns in somatosensory cortex because the movements performed in either condition are very similar. Meanwhile, we might expect Grasp and Arm to be dissimilar to Eye movements, because they are entirely different forms of movement.\n",
    "\n",
    "Basic RSA is more straightforward to code than basic pattern classification. At minimum, we need one representative pattern of voxels per condition. More sophisticated (and more common) approaches obtain one representative pattern per condition _per run_ in order to cross-validate the patterns for estimating pattern reliability/stability. For the sake of this course and the final project, we'll stick with the minimal approach of one pattern per condition. This is very convenient, because we already have those patterns in our first-level model. Instead of averaging voxel activity within conditions and comparing means, as in an ROI analysis, we'll simply correlate voxel activity between conditions.\n",
    "\n",
    "First, let's import our dependencies. We have seen many of these before. Some extra scipy modules are imported for correlations and ways to analyze RSA data. There are many ways to compute correlations in Python, and we'll use `pearsonr` to compute an example Pearson correlation. However, we'll mainly use numpy's `corrcoef` function to compute pairwise correlations simply because it is very convenient for generating correlation matrices. We'll be using some nice functions from seaborn to visualize our RSA results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "\n",
    "# useful for correlations and RDM analysis\n",
    "from scipy import spatial, stats, cluster\n",
    "\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn import image\n",
    "from nilearn.plotting import plot_roi\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the first-level models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_level_models.p', 'rb') as f:\n",
    "    glms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract ROI voxel patterns\n",
    "\n",
    "We need to get voxel patterns from the ROI we wish to analyze. Below is code that should be familiar by now (see `7_ROI_Analysis.ipynb`). We will iterate through task conditions, and get the parameter maps (betas). Then we'll extract the voxels from the ROI. Each iteration will produce a subject-by-voxel array. We'll save that array each iteration to `pattern_list`. Finally, we'll convert this list to a numpy array, making it easy to analyze.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_img = 'L_SSc.nii.gz'\n",
    "conditions = ['Arm', 'Eye', 'Finger', 'Grasp', 'Mouth', 'Speech', 'Toes', 'Touch']\n",
    "\n",
    "pattern_list = []\n",
    "for cond in conditions:\n",
    "    \n",
    "    # 1. get parameter map of each subject \n",
    "    param_maps = []\n",
    "    for model in glms:\n",
    "        parameter_map = model.compute_contrast(cond, output_type='effect_size')\n",
    "        param_maps.append(parameter_map)\n",
    "        \n",
    "    # 2. resample ROI mask to functional resolution (2x2x2 -> 3x3x4) \n",
    "    roi = image.resample_to_img(roi_img, param_maps[0], \n",
    "                                interpolation='nearest')\n",
    "    \n",
    "    # 3. set masker and extract voxels\n",
    "    masker = NiftiMasker(mask_img=roi)\n",
    "    roi_data = masker.fit_transform(param_maps)\n",
    "    \n",
    "    # 4. add extracted data to list\n",
    "    pattern_list.append(roi_data)\n",
    "    \n",
    "    \n",
    "# convert to 3D array\n",
    "pattern_array = np.array(pattern_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition x subject x voxel array\n",
    "pattern_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple correlation analysis\n",
    "\n",
    "To simply illustrate the correlation approach, we'll take two conditions of a single subject and correlate the voxels' parameter values between condition. Let's get the Arm (index = 0) and Grasp (index = 3) condition from one subject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm = pattern_array[0, 1, :]\n",
    "grasp = pattern_array[3, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = stats.pearsonr(arm, grasp)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(arm, grasp)\n",
    "ax.set(xlabel='Arm', ylabel='Grasp', title=f'r = {r}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above scatter plot is showing you the correlation between Grasp and Arm. Each data point is a voxel's parameter value (beta) for either condition. Now let's correlate arm with eye (index = 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = pattern_array[1, 1, :]\n",
    "\n",
    "r, p = stats.pearsonr(arm, eye)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(arm, eye)\n",
    "ax.set(xlabel='Arm', ylabel='Eye', title='r = {}'.format(r));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subject, the corretion for Arm and Grasp > the correlation for Arm and Eye. \n",
    "\n",
    "## 3. Pairwise correlations and dissimilarity matrices\n",
    "\n",
    "### 3.1 Correlation matrix\n",
    "The next step is to perform this correlation for all pairs of conditions for this subject. Numpy has a convenient function called `corrcoef` that lets us compute pairwise correlations in a 2D matrix (where each row = condition, each col = observation/voxel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(pattern_array[:, 1, :])\n",
    "corr_matrix = pd.DataFrame(corr_matrix, columns=conditions, index=conditions)\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our results using seaborn's `heatmap` function (see [documentation](https://seaborn.pydata.org/generated/seaborn.heatmap.html#seaborn.heatmap))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix, cmap='viridis', square=True)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.title('Correlation Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Arm and Grasp are highly correlated. Meanwhile, for example, Touch and Eye are the least correlated. \n",
    "\n",
    "### 3.2 Representational Dissimilarity Matrix\n",
    "\n",
    "In RSA, it's common to convert correlation matrices to dissimilarity matrices, otherwise known as _Representational Dissimilarity Matrices_ (RDM). We simply subtract our correlations from 1:\n",
    "\n",
    "$RDM = 1 - \\text{correlation matrix}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This flips the scale, where larger numbers reflect more dissimilar conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissim_matrix = 1 - corr_matrix\n",
    "\n",
    "sns.heatmap(dissim_matrix, cmap='viridis', square=True)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.title('RDM');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this is the exact same as above, just that everything has been flipped. Eye and Touch are the _most dissimilar_, and Arm and Grasp are the _least dissimilar_. So, the dissimilarity is a measure of the distance between conditions. We can cluster conditions according to their dissimilarity with helpful scipy functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get upper triangle\n",
    "distances = spatial.distance.squareform(dissim_matrix, checks=False)\n",
    "\n",
    "# apply hierarchical clustering \n",
    "linkages = cluster.hierarchy.linkage(distances, method='average')\n",
    "\n",
    "# plot dendogram\n",
    "dendo = cluster.hierarchy.dendrogram(linkages, labels=conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine our dissimilarity matrix with a dendogram using seaborn's `clustermap` function (see [documentation](https://seaborn.pydata.org/generated/seaborn.clustermap.html#seaborn.clustermap)). We need to pass in our RDM, and the linkage information we obtained above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(dissim_matrix, cmap='viridis', row_linkage=linkages, \n",
    "               col_linkage=linkages, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Group Analysis\n",
    "\n",
    "The next step is to repeat the pairwise correlation step for all subjects, so that each subject will have a correlation matrix. We can analyze the average correlation matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = []\n",
    "for i in range(8):\n",
    "    corr_mat = np.corrcoef(pattern_array[:, i, :])\n",
    "    matrices.append(corr_mat)\n",
    "matrices = np.array(matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean across subjects\n",
    "mean_corr_matrix = np.mean(matrices, axis=0)\n",
    "# convert to DataFrame for seaborn\n",
    "mean_corr_matrix = pd.DataFrame(mean_corr_matrix, index=conditions, \n",
    "                                columns=conditions)\n",
    "\n",
    "sns.heatmap(mean_corr_matrix, cmap='viridis', square=True)\n",
    "plt.title('Average correlation matrix');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert this to the average RDM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dissim_matrix = 1 - mean_corr_matrix\n",
    "sns.heatmap(mean_dissim_matrix, cmap='viridis', square=True)\n",
    "plt.title('Average RDM');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we did with a single subject, we can apply hierarchical clustering to the mean dissimilarity matrix and get a sense of the relational structure of the conditions across the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get upper triangle\n",
    "distances = spatial.distance.squareform(mean_dissim_matrix, checks=False)\n",
    "\n",
    "# apply hierarchical clustering \n",
    "linkages = cluster.hierarchy.linkage(distances, method='average')\n",
    "\n",
    "# plot dendogram\n",
    "dendo = cluster.hierarchy.dendrogram(linkages, labels=conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(mean_dissim_matrix, cmap='viridis', row_linkage=linkages, \n",
    "               col_linkage=linkages, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing RDM Models\n",
    "\n",
    "Analyzing the mean dissimilarity is useful to understand the structure of the data. We can also test specific _a priori_ models and if the model fits the data well, or better than other models.  \n",
    "\n",
    "\n",
    "The first step is to specify a model RDM, in which we set elements to 1 if we expect them to be  dissimilar, and 0 if we expect them to be similar. For instance, if we set all off-diagonal elements to 1, then we expect that everything is dissimilar -- the ROI distinctly represents each condition.  \n",
    "\n",
    "The second step is to take the model RDM and vectorize it (i.e. flatten it to a big vector), and do the same for each subject's RDM. Then, we correlate the vectorized model RDM with each subject's vectorized RDM to get an _r_ value per subject. We can test those _r_ values to determine if the model is good fit. \n",
    "\n",
    "**Model 1**  \n",
    "This model specifies that all conditions are distinctly represented. Note that if we were doing doing cross-validation across functional runs, we would expect the diaganonal to vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_1 = np.zeros(shape=(8, 8)) + 1\n",
    "np.fill_diagonal(rdm_1, 0)\n",
    "rdm_1 = pd.DataFrame(rdm_1, index=conditions, columns=conditions, dtype=int)\n",
    "rdm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rdm_1, cmap='viridis', square=True)\n",
    "plt.title('Model 1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2**  \n",
    "This model assumes that Arm and Grasp are correlated, and the remaining conditions (Toes, Finger, Touch, Eye, Mouth and Speech) are separately correlated. Note that this model reflects the first branching of the dendogram above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_2 = np.zeros(shape=(8, 8)) + 1\n",
    "np.fill_diagonal(rdm_2, 0)\n",
    "rdm_2[(3, 0, 1, 2), (0, 3, 2, 1)] = 0\n",
    "rdm_2[4:, 4:] = 0\n",
    "rdm_2[4:, 1:3] = 0\n",
    "rdm_2[1:3, 4:] = 0\n",
    "\n",
    "rdm_2 = pd.DataFrame(rdm_2, index=conditions, columns=conditions, dtype=int)\n",
    "rdm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rdm_2, cmap='viridis', square=True)\n",
    "plt.title('Model 2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 3**  \n",
    "This model assumes that 1) Arm and Grasp are similar, 2) Toes, Finger and Touch are similar, and 3) Eye, Mouth, and Speech are similar. This reflects the 3 main clusters from the dendograms above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_3 = np.zeros(shape=(8, 8)) + 1\n",
    "np.fill_diagonal(rdm_3, 0)\n",
    "rdm_3[(3, 0), (0, 3)] = 0\n",
    "rdm_3[6:, 6:] = 0\n",
    "rdm_3[6:, 2] = 0\n",
    "rdm_3[2, 6:] = 0\n",
    "rdm_3[1, 4:6] = 0\n",
    "rdm_3[4:6, 1] = 0\n",
    "rdm_3[4:6, 4:6] = 0\n",
    "\n",
    "rdm_3 = pd.DataFrame(rdm_3, index=conditions, columns=conditions, dtype=int)\n",
    "rdm_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rdm_3, cmap='viridis', square=True)\n",
    "plt.title('Model 3');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**  \n",
    "Now lets write a function to correlate subject matrices with each model matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, subject_matrices):\n",
    "    r_values = []\n",
    "    # iterate through subjects\n",
    "    for mat in subject_matrices:\n",
    "        # convert to RDM\n",
    "        rdm = 1 - mat\n",
    "        # correlate\n",
    "        r, p = stats.pearsonr(model.values.ravel(), rdm.ravel())\n",
    "        r_values.append(r)\n",
    "    return r_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(rdm_3, matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot each result. We'll make a dataframe that has a subject column and a column for each model. We can shape that and feed it into a seaborn plot: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe\n",
    "df = pd.DataFrame({'subject': range(8),\n",
    "                   'model 1': test_model(rdm_1, matrices), \n",
    "                   'model 2': test_model(rdm_2, matrices), \n",
    "                   'model 3': test_model(rdm_3, matrices)})\n",
    "df = df.melt(id_vars='subject', var_name='model', value_name='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with data point overlay\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x='model', y='r', data=df, ci=68, color='dodgerblue', ax=ax, \n",
    "             errcolor='k', errwidth=1.5)\n",
    "sns.stripplot(x='model', y='r', data=df, color='k', ax=ax)\n",
    "ax.set_title('Model comparison')\n",
    "# add 0 line and tidy up aesthetics\n",
    "ax.axhline(0, c='k', lw=1)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "sns.despine(bottom=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psyc917-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
