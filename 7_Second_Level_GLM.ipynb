{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second-Level GLM Analysis and Multiple Comparisons\n",
    "\n",
    "In the previous lesson we ran a first-level analysis on our data set. Each subject's activity was modeled using GLMs, and we saved those models to `first_level_models.p`. The next step is to combine these models to examine within-subject effects consistent across the group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nistats.second_level_model import SecondLevelModel\n",
    "from nistats.thresholding import map_threshold\n",
    "from nistats.reporting import get_clusters_table, make_glm_report\n",
    "from nilearn.plotting import view_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_level_models.p', 'rb') as f:\n",
    "    glms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Second Level Analysis\n",
    "\n",
    "Second-level analysis is easily done with nistats' `SecondLevelModel` class [see online documentation](https://nistats.github.io/modules/generated/nistats.second_level_model.SecondLevelModel.html#nistats.second_level_model.SecondLevelModel). Like with `FirstLevelModel`, we define and then fit our second-level model. The first-level models we ran and saved last lesson will serve as inputs when fitting the second-level model.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level = SecondLevelModel()\n",
    "second_level.fit(glms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, second-level analysis is much faster than first-level analysis. This is because this dataset is all within-subjects, so all the heavy-lifting was done in the first-level analysis. If we had two different groups that we wanted to compare, then second-level analysis would have a greater role.\n",
    "\n",
    "Next, we can compute a group contrasts to examine our group effects. Because we're looking for voxels that are consistently activated across subjects, we want to see if each voxel is significantly greater (or less) than 0. This is done by running a one-sample t-test for each voxel where we test against 0. Each voxel has 8 observations (the number of subjects), so the degrees of freedom for each voxel equals 7. \n",
    "\n",
    "By default, nistats convert the results to _z_-values and output a _z_ map. We can change this back to _t_ values using the `output_type` parameter. Both _z_ or _t_ maps are common; either works. We'll stick with _z_ values for now.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map = second_level.compute_contrast(first_level_contrast='Finger', \n",
    "                                      second_level_stat_type='t', \n",
    "                                      output_type='z_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_img(z_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can threshold our map such that we only show significantly activated voxels, using _p_ < .05 (_z_ > 1.96)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_img, thresh = map_threshold(z_map, threshold=1.96, height_control=None)\n",
    "view_img(thresh_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to showing our results, we need to give information about the significant clusters we obtained. We want to report cluster location, size, and the magnitude of it's activity. We can get all of this cluster information from the `get_clusters_table` function in the `reporting` module.\n",
    "\n",
    "Because we're interesed in _clusters_ of voxels, rather than random isolated voxels that pass the significance threshold, we can use `cluster_threshold` to set the minimum number of required contiguous voxels.\n",
    "\n",
    "This function will return a pandas DataFrame with all of the information we need to report in a paper (other than the anatomical location):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_clusters_table(z_map, stat_threshold=1.96, cluster_threshold=10)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multiple Comparisons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
